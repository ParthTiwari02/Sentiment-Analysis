{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbyIhvzcaF0L",
        "outputId": "cecfce67-2179-4005-90ba-9459952e470b"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_YGb5HzaOt1"
      },
      "source": [
        "X_train = [\"This was an awesome movie\",\n",
        "            \"Great Movie I liked it alot\",\n",
        "            \"Happy ending! awesome acting by hero\",\n",
        "            \"Loved it\",\"Truly great\",\n",
        "            \"Not bad, upto the mark\",\n",
        "            \"Could have been better\",\n",
        "            \"Surely a Disappointing movie\"]\n",
        "            \n",
        "y_train = [1,1,1,1,1,0,0,0]          #1-Positive  0-Negative\n",
        "\n",
        "X_test = [\"I was happy after movie\",\"Love the acting\",\"The movie was bad\"]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uhfvq60DaRzP",
        "outputId": "1ab83ae1-7a04-46a7-9a50-174b92913ad4"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This was an awesome movie',\n",
              " 'Great Movie I liked it alot',\n",
              " 'Happy ending! awesome acting by hero',\n",
              " 'Loved it',\n",
              " 'Truly great',\n",
              " 'Not bad, upto the mark',\n",
              " 'Could have been better',\n",
              " 'Surely a Disappointing movie']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtsWpoWpaXLv"
      },
      "source": [
        "**Data Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnooUw9oaV1n"
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uyJh95LavJe",
        "outputId": "af06ea55-ce47-4e7c-81e7-ee8976a7f233"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pDP5qBRa76-"
      },
      "source": [
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "en_stopwords = set(stopwords.words(\"english\"))\n",
        "ps = PorterStemmer()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvDeEUbcbEni"
      },
      "source": [
        "def getcleandata(text):\n",
        "  text = text.lower()\n",
        "\n",
        "  #tokenize\n",
        "  tokens = tokenizer.tokenize(text)\n",
        "  new_tokens = [token for token in tokens if token not in en_stopwords]\n",
        "  stemmed_tokens = [ps.stem(token) for token in new_tokens ]\n",
        "\n",
        "  clean_text = \" \".join(stemmed_tokens)\n",
        "  return clean_text"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnjYhWE9biYv"
      },
      "source": [
        "X_clean = [getcleandata(i) for i in X_train]\n",
        "Xtest_clean = [getcleandata(i) for i in X_test]"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN7C26Ahcon3",
        "outputId": "7607009f-1d5f-4364-c1ac-31cef09a60bb"
      },
      "source": [
        "X_clean"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['awesom movi',\n",
              " 'great movi like alot',\n",
              " 'happi end awesom act hero',\n",
              " 'love',\n",
              " 'truli great',\n",
              " 'bad upto mark',\n",
              " 'could better',\n",
              " 'sure disappoint movi']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBG2fevbehWt"
      },
      "source": [
        "**Vectorisation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRUDXW0EeTqs"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRZqoeNfetrA"
      },
      "source": [
        "cv = CountVectorizer(ngram_range=(1,2))\n",
        "X_vec = cv.fit_transform(X_clean).toarray()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmtKCa53fpNr",
        "outputId": "8c4ce1f7-bf7b-4009-81bc-6f87f2c17e76"
      },
      "source": [
        "print(cv.get_feature_names())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['act', 'act hero', 'alot', 'awesom', 'awesom act', 'awesom movi', 'bad', 'bad upto', 'better', 'could', 'could better', 'disappoint', 'disappoint movi', 'end', 'end awesom', 'great', 'great movi', 'happi', 'happi end', 'hero', 'like', 'like alot', 'love', 'mark', 'movi', 'movi like', 'sure', 'sure disappoint', 'truli', 'truli great', 'upto', 'upto mark']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcxWjG9Bfzvx"
      },
      "source": [
        "Xtest_vec = cv.transform(Xtest_clean).toarray()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwfiRbWTgeMc"
      },
      "source": [
        "**Multinomial Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NyT5XAmgRbc"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9dSGGhogp7p",
        "outputId": "c19f0450-36ec-4358-a8b5-e0f9e35c7b3d"
      },
      "source": [
        "mn = MultinomialNB()\n",
        "mn.fit(X_vec, y_train)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARvGsDi9g4mU"
      },
      "source": [
        "y_pred = mn.predict(Xtest_vec)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4zQfFEWhheW",
        "outputId": "3fc49fbf-2828-4026-d7e8-b6c95864763b"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnziY5yzhlP5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}